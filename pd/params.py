
import os 
import sys 
import pickle 
from pathlib import Path
import pandas as pd

BATCH_SIZE = 20000

## log 
PerfThreshold = 0.84
valThreshold = 0.78
logBestIndiv = 20


# dirs
DATADIR = None
OUTDIR = None
if sys.platform == "darwin":
    DATADIR = "/Users/nimamanaf/Desktop/kaggle/pd/data/"
    OUTDIR = "/Users/nimamanaf/Desktop/kaggle/pd/data/out/"
    MODELDIR = "/Users/nimamanaf/Desktop/kaggle/pd/data/out/Models/"
elif sys.platform == 'win32':
    DATADIR = "C:\\Users\\20204069\\Desktop\\Kaggle\\pd\\data\\"
    OUTDIR = "C:\\Users\\20204069\\Desktop\\Kaggle\\pd\\data\\out\\"
    MODELDIR = "C:\\Users\\20204069\\Desktop\\Kaggle\\pd\\data\\Models\\"

elif sys.platform == 'linux':
	#DATADIR = "/home/tue/20204069/pd/data/"
	#OUTDIR = "/home/tue/20204069/pd/data/out/"
	#MODELDIR = "/home/tue/20204069/pd/data/Models/"
    
	DATADIR = "/home/nimamd/pd/data/"
	OUTDIR = "/home/nimamd/pd/data/out/"
	MODELDIR = "/home/nimamd/pd/data/Models/"

TRAINDATA = DATADIR + "train_data.parquet"
TESTDATA = DATADIR + "test_data.parquet"
TRAINLABELS = DATADIR+'train_labels.csv'
if not os.path.exists(MODELDIR):
    os.makedirs(MODELDIR)
PREDDIR = DATADIR+"PRED/"
if not os.path.exists(PREDDIR):
    os.makedirs(PREDDIR)

if not os.path.exists(os.path.join(PREDDIR, "train_pred.csv")):
	train_labels = pd.read_csv(TRAINLABELS)
	train_labels.set_index("customer_ID").to_csv(os.path.join(PREDDIR, "train_pred.csv"))
	pd.DataFrame({"customer_ID":pd.read_parquet(TESTDATA).customer_ID.unique()}).to_csv(os.path.join(PREDDIR, "test_pred.csv"))

try:
	with open(OUTDIR+"col_info.pkl", "rb") as f:
		col_info = pickle.load(f)
except Exception as e:
	print(e)

try:
	with open(OUTDIR+"col_info13.pkl", "rb") as f:
		col_info13 = pickle.load(f)
except Exception as e:
	print(e)


# data
dataCols = ['customer_ID', 'S_2', 'P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41','B_3',
 	'D_42', 'D_43','D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49',
 	'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5',
 	'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5',
 	'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65',
 	'B_16',  'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21',
 	'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74','D_75','D_76','B_24',
	'R_7', 'D_77','B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10','R_11', 'B_27', 'D_81',
 	'D_82','S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18',
	'D_86','D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21',
	'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22',
	'S_23','S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36',
 	'B_37', 'R_26', 'R_27', 'B_38','D_108','D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40',
 	'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121',
 	'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131','D_132',
 	'D_133','R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144',
	'D_145']
featureCols = [col for col in dataCols if col not in ["customer_ID", "S_2"]]
CATCOLS = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']
ContCols = [col for col in dataCols if col not in CATCOLS + ["customer_ID", "S_2", "target"]]
MostNaNCols = ['D_42', 'D_50', 'D_53', 'D_73', 'D_76', 'B_29', 'D_88', 'D_110', 'B_39', 'B_42', 'D_132', 'D_134', 'D_142']

bestCols = ["P_2", "D_48", "R_1", "D_44", "B_2", "B_9"]

## A set of cols created by me looking into thre distribution of the customers who deafult and customers who don't
ManCols = ["P_2", "B_1", "B_2", "R_1", "S_3", "D_41", "B_3", 
	"D_42", "D_43", "D_44", "B_4", "D_45", "B_5", "R_2", 
	"D_46", "D_47", "D_48", "D_49", "B_6", "B_7", "B_8", 
	"D_50", "D_51", 'B_9', "R_3", "D_52", "P_3", "B_10",
	"D_53", "S_5", "B_11", "S_6", "R_4", "S_7", "B_12", 
	"S_8", "D_55", "D_56", "D_58", "D_59", "D_60", "D_61",
	"S_11", "D_62", "D_64", "B_16", "B_17", "B_18", "B_19", 
	"B_20", "D_68", "B_22", "D_70", "S_15", "B_23", "D_74", 
	"D_75", "D_76", "D_78", "D_79", "B_28", "B_30", "B_33", 
	"S_22", "S_23", "S_24", "B_37", "R_26", "B_38", "B_40", 
	"D_124", "D_128", "D_129"]
    

betterTransFeatsK79 = ['R_3', 'D_42', 'R_16', 'R_27', 'D_59', 'P_4', 'D_79', 'D_122',
       'D_64', 'D_113', 'D_68', 'R_26', 'R_11', 'D_120', 'D_89', 'S_6',
       'D_91', 'D_124', 'D_114', 'D_123', 'D_129', 'D_125', 'D_107',
       'D_103', 'D_83', 'R_9', 'B_21', 'D_143', 'D_139', 'S_16', 'D_116',
       'D_63', 'B_24', 'D_140', 'R_21', 'D_66', 'S_26', 'S_20', 'S_17',
       'S_19', 'B_31', 'D_82', 'D_108', 'B_27', 'B_36', 'D_96', 'D_94',
       'D_86', 'D_111', 'D_73', 'D_93', 'D_87', 'R_28', 'D_109', 'S_18',
       'R_23', 'R_18']

agg = {0: "Use only the features from K79",
		1:"ONly use the transformation from k79 for the cat data",
	 	2:"Transform all the other features with in addition to the cat data that have better SFA", 
		3: "Combine fearture that perofrm better with 13 with features from K79", 
		4: "set thresholds using the sfa"}


sfa_gbm = {'P_2': [0.6441301676682678, 0.8336452614482266, 0.45461507388830913],
 'B_2': [0.5639876879906887, 0.7633054328703259, 0.3646699431110513],
 'R_1': [0.5629148468527565, 0.7042455552869584, 0.4215841384185546],
 'D_48': [0.5625330523098035, 0.7696700700149686, 0.35539603460463864],
 'B_9': [0.5607010189225262, 0.7354239855341493, 0.38597805231090315],
 'D_44': [0.5474030856096406, 0.7470261867038471, 0.34777998451543407],
 'D_55': [0.5217580675637289, 0.7398082548298848, 0.30370788029757295],
 'D_61': [0.5185972141350096, 0.736061698610343, 0.3011327296596762],
 'B_3': [0.5182287264458822, 0.7388087505657134, 0.2976487023260511],
 'B_18': [0.5161078990550017, 0.7531233283217378, 0.2790924697882654],
 'B_1': [0.5146965815455187, 0.7322409767376525, 0.29715218635338475],
 'B_37': [0.5140818700027292, 0.7305823618790909, 0.29758137812636754],
 'B_11': [0.5080672019533305, 0.7245448795521318, 0.29158952435452923],
 'D_75': [0.5036648000124822, 0.7275554727149026, 0.2797741273100616],
 'B_14': [0.4939503541755779, 0.7034475491630857, 0.2844531591880701],
 'B_7': [0.4931137172532085, 0.7266169050015865, 0.2596105295048305],
 'B_23': [0.4925619617265763, 0.7254292386987177, 0.25969468475443497],
 'B_4': [0.4921459493588963, 0.706251369549583, 0.27804052916820954],
 'B_6': [0.4914245918036604, 0.7262934896631325, 0.25655569394418826],
 'B_38': [0.4907128827643386, 0.7080053595637531, 0.2734204059649241],
 'B_25': [0.4812283534174992, 0.6624264109451408, 0.30003029588985763],
 'D_74': [0.47079908149373273, 0.6760126107607176, 0.2655855522267479],
 'D_62': [0.46996393320910645, 0.6910387157129919, 0.248889150705221],
 'D_58': [0.46883214212903757, 0.6758068095888052, 0.2618574746692699],
 'B_10': [0.46648714116516254, 0.7106024507754727, 0.22237183155485238],
 'D_39': [0.4644332458099751, 0.6106839083904083, 0.31818258322954185],
 'B_16': [0.4589638927460773, 0.6822173468749937, 0.23571043861716093],
 'B_40': [0.45611820112355017, 0.6856231461121827, 0.2266132561349177],
 'B_19': [0.45402634515663465, 0.6256360881656273, 0.28241660214764197],
 'P_3': [0.45337998632122417, 0.5941821290365642, 0.31257784360588414],
 'S_25': [0.45075721442955075, 0.5567135401796657, 0.3448008886794358],
 'B_20': [0.449109810706905, 0.6750146528878733, 0.22320496852593666],
 'R_10': [0.4441129033073453, 0.5395116988286469, 0.34871410778604367],
 'B_33': [0.4433631142139504, 0.6908128073486939, 0.19591342107920692],
 'B_28': [0.44126268696556226, 0.6555334191729867, 0.22699195475813783],
 'S_23': [0.439327854294315, 0.5447445092080125, 0.33391119938061736],
 'S_22': [0.4319216880888098, 0.6300516772514406, 0.23379169892617901],
 'D_78': [0.4313665053795992, 0.5277446241836439, 0.3349883865755546],
 'B_17': [0.4225103776880227, 0.6000700703523136, 0.24495068502373177],
 'D_60': [0.4216691937076127, 0.6228432179265526, 0.2204951694886727],
 'D_77': [0.4195631612211046, 0.6177896004574918, 0.2213367219847174],
 'B_22': [0.4193196714947055, 0.6179085388018458, 0.22073080418756522],
 'R_2': [0.4142409091473399, 0.4604120030996079, 0.36806981519507187],
 'B_30': [0.4116510437666555, 0.5900742287794819, 0.23322785875382906],
 'S_24': [0.4099682863024121, 0.5996854533400044, 0.22025111926481974],
 'S_8': [0.3969018831022184, 0.5847621261869325, 0.2090416400175043],
 'D_46': [0.39676488001388743, 0.5671268920168683, 0.22640286801090653],
 'S_3': [0.3931637099766104, 0.5824949898862332, 0.2038324300669876],
 'S_7': [0.38676403520081915, 0.5794828958636506, 0.19404517453798767],
 'D_41': [0.38552795183431976, 0.4614319093238723, 0.30962399434476723],
 'S_15': [0.38508174730364836, 0.5733832744571637, 0.19678022015013297],
 'R_6': [0.3818681225335392, 0.4300775114352745, 0.3336587336318039],
 'D_70': [0.37424076652838767, 0.5318659205748687, 0.2166156124819066],
 'D_53': [0.3720593029269079, 0.4145329863028683, 0.32958561955094756],
 'D_84': [0.3629332118873331, 0.4158553152817183, 0.3100111084929478],
 'R_5': [0.36266132296077846, 0.40488470200261534, 0.32043794391894165],
 'B_26': [0.36160903621498874, 0.4319062603991429, 0.2913118120308345],
 'D_65': [0.3607826635021903, 0.43448652402865096, 0.28707880297572963],
 'R_4': [0.3602626992812536, 0.400962669239452, 0.3195627293230552],
 'R_7': [0.36007587593182155, 0.40148948371135573, 0.3186622681522873],
 'S_5': [0.3515509271583871, 0.5257530813003134, 0.17734877301646076],
 'B_5': [0.34936253257843786, 0.5290428353793821, 0.16968222977749353],
 'R_8': [0.34819535322394185, 0.39053686728539677, 0.30585383916248693],
 'D_52': [0.3429087364575158, 0.5171030285079895, 0.1687144444070421],
 'R_3': [0.33868993842229833, 0.45678372105639864, 0.22059615578819808],
 'D_112': [0.3365873227711649, 0.44045171828612756, 0.23272292725620225],
 'D_42': [0.32750263369134025, 0.3827966970120608, 0.27220857037061974],
 'D_43': [0.32548104352499985, 0.43232674857758574, 0.2186353384724139],
 'S_27': [0.3145593380248224, 0.4678014780828357, 0.16131719796680916],
 'D_45': [0.2968431260460747, 0.4682780991315677, 0.1254081529605817],
 'S_11': [0.2897639373522203, 0.44464384063839546, 0.13488403406604504],
 'D_71': [0.28971050918702207, 0.4523550069962544, 0.12706601137778975],
 'R_16': [0.28865440816395677, 0.37929151400859484, 0.1980173023193187],
 'R_27': [0.28314398178410405, 0.31639736539269386, 0.24989059817551418],
 'B_13': [0.2831274243979889, 0.4277773855718218, 0.1384774632241559],
 'D_47': [0.2824239066907431, 0.42318928172228126, 0.1416585316592049],
 'S_13': [0.27800576988450193, 0.41212289399528046, 0.14388864577372337],
 'R_15': [0.2779665654594162, 0.32321020366263026, 0.23272292725620225],
 'D_72': [0.2755933027936595, 0.3168394820137505, 0.23434712357356852],
 'B_8': [0.27363000974131046, 0.4240062409119137, 0.12325377857070724],
 'D_59': [0.2663340297256868, 0.37393442764742174, 0.15873363180395192],
 'D_51': [0.2645206102729434, 0.4109966519256962, 0.11804456862019053],
 'D_81': [0.2585601119345927, 0.2944622644656779, 0.22265795940350758],
 'B_12': [0.25836175080944834, 0.37312098369382857, 0.14360251792506817],
 'P_4': [0.2582684722242482, 0.32050570601984324, 0.1960312384286532],
 'R_13': [0.2536825424673801, 0.281795353894938, 0.22556973103982225],
 'R_26': [0.24652703861730008, 0.28203478885139077, 0.21101928838320935],
 'D_131': [0.24347707543373937, 0.31425074762918476, 0.172703403238294],
 'D_89': [0.24117807787835785, 0.27523325543019334, 0.20712290032652236],
 'D_79': [0.23990324961530246, 0.3085673973354287, 0.17123910189517622],
 'D_64': [0.2385463813770376, 0.3423012994625951, 0.13479146329148012],
 'S_12': [0.23666676614449353, 0.35293261667987136, 0.1204009156091157],
 'D_117': [0.23591544717115245, 0.33817552692048514, 0.13365536742181977],
 'D_115': [0.23396240541149851, 0.3394702378267335, 0.1284545729962635],
 'D_118': [0.23169964075711097, 0.3362575304117882, 0.12714175110243378],
 'D_49': [0.23125261932809876, 0.2908706070878803, 0.17163463156831724],
 'D_106': [0.23083288152186576, 0.290872683971459, 0.17079307907227254],
 'D_102': [0.23014634699768255, 0.3086365186831491, 0.15165617531221598],
 'D_119': [0.23010561061432427, 0.33386894499745723, 0.1263422762311913],
 'R_20': [0.22941422411948187, 0.26290661163479634, 0.19592183660416737],
 'R_24': [0.2289395189323103, 0.2612334661138548, 0.1966455717507658],
 'D_130': [0.22882906343219497, 0.31240616604707416, 0.14525196081731578],
 'D_132': [0.22856702071471788, 0.29049823168762406, 0.1666358097418117],
 'R_14': [0.22836031339348056, 0.261875977377731, 0.19484464940923016],
 'D_122': [0.22783246890676356, 0.32514856120195407, 0.13051637661157303],
 'D_120': [0.2276108544733494, 0.30053594464872185, 0.1546857642979769],
 'D_68': [0.22720321707052432, 0.32782852321096484, 0.12657791093008383],
 'D_54': [0.22628876007217053, 0.253819651628503, 0.19875786851583802],
 'R_11': [0.22466029574626656, 0.29509768106738077, 0.15422291042515232],
 'D_114': [0.22334458404658536, 0.3134714079692942, 0.13321776012387654],
 'D_128': [0.22009135805477184, 0.31885609275477883, 0.12132662335476486],
 'D_133': [0.2199279724215491, 0.2804743176171918, 0.15938162722590635],
 'D_121': [0.21548699658997622, 0.3113641369171188, 0.11960985626283367],
 'R_17': [0.21526318448667173, 0.2398305733696137, 0.19069579560372976],
 'D_113': [0.21414416616379772, 0.30066689630241616, 0.12762143602517925],
 'S_6': [0.21077300201590685, 0.30706120246989227, 0.11448480156192144],
 'R_9': [0.20123149934778192, 0.24180221167566954, 0.1606607870198943],
 'D_56': [0.20100804045876308, 0.32917129685989666, 0.07284478405762951],
 'D_124': [0.20068526137422887, 0.27954738342102653, 0.12182313932743125],
 'D_91': [0.2006707218228903, 0.26941967436581293, 0.13192176927996768],
 'D_138': [0.19554096879925112, 0.23040431952868703, 0.1606776180698152],
 'D_136': [0.19553113852225446, 0.2304688142242982, 0.16059346282021073],
 'D_137': [0.19518644376451294, 0.2304021735558882, 0.15997071397313764],
 'D_135': [0.19516129924058723, 0.23039396213283905, 0.1599286363483354],
 'S_9': [0.192508694787317, 0.2895264278484415, 0.09549096172619248],
 'B_21': [0.1899958750758503, 0.21126889021969805, 0.16872285993200256],
 'D_107': [0.18962402467504658, 0.2592510789390789, 0.11999697041101424],
 'S_16': [0.18749038626815223, 0.21021320933571197, 0.16476756320059247],
 'D_103': [0.18699522409765398, 0.2543300987827116, 0.11966034941259636],
 'D_129': [0.1865461080760586, 0.2593563963116755, 0.11373581984044165],
 'D_104': [0.1861768619883915, 0.2575407169414042, 0.11481300703537886],
 'D_127': [0.1841720951483164, 0.2728363975205194, 0.09550779277611338],
 'R_21': [0.18195117758380283, 0.20268614350032185, 0.1612162116672838],
 'D_50': [0.1788552468611977, 0.27177115282631026, 0.0859393408960851],
 'B_24': [0.1753027448462163, 0.20925833245676423, 0.14134715723566837],
 'B_32': [0.17510289659045236, 0.2212126265871726, 0.1289931665937321],
 'D_123': [0.17457436961769923, 0.2322739285847101, 0.11687481065068839],
 'D_145': [0.1741536916609861, 0.2370709743947833, 0.11123640892718888],
 'D_125': [0.17395039195680523, 0.23131210111157724, 0.11658868280203319],
 'D_69': [0.17374360613018588, 0.22693481720196804, 0.12055239505840375],
 'D_126': [0.1730182844248676, 0.23181264856158765, 0.11422392028814757],
 'R_12': [0.1704421669823783, 0.20009260137647777, 0.14079173258827885],
 'D_143': [0.1687346285703783, 0.23110543716566653, 0.10636381997509005],
 'D_139': [0.16863701644484733, 0.23099436816420907, 0.10627966472548557],
 'B_15': [0.1685612769876518, 0.23637188914883173, 0.10075066482647188],
 'D_83': [0.16802580349381901, 0.21858770958971832, 0.11746389739791968],
 'D_141': [0.16764266575598818, 0.23338173976592327, 0.10190359174605312],
 'S_26': [0.16621859673780848, 0.22965838713367734, 0.10277880634193962],
 'D_92': [0.1633123617520506, 0.2315966156507333, 0.09502810785336789],
 'S_20': [0.16251809930657807, 0.18338608247891172, 0.14165011613424444],
 'D_80': [0.15540814956003368, 0.20526878506614069, 0.10554751405392668],
 'D_140': [0.15411045873571555, 0.18896451325693622, 0.1192564042144949],
 'D_105': [0.14936268857766352, 0.19127595446033935, 0.10744942269498771],
 'D_116': [0.1472694599496536, 0.180096195962188, 0.1144427239371192],
 'D_63': [0.14722984422477806, 0.1973361148810369, 0.09712357356851921],
 'D_134': [0.1457930731224208, 0.1299828204293772, 0.16160332581546435],
 'B_41': [0.14561074103271437, 0.17250367144840248, 0.11871781061702628],
 'R_22': [0.14509954696254207, 0.17046300478784376, 0.11973608913724038],
 'R_25': [0.1440245679408852, 0.1680269188958748, 0.12002221698589557],
 'B_31': [0.1439463168092935, 0.1674496403846691, 0.12044299323391792],
 'R_19': [0.14091658602459808, 0.1670201650138173, 0.11481300703537886],
 'S_17': [0.13803584443454478, 0.1818009782621619, 0.09427071060692765],
 'D_82': [0.13053927863704123, 0.16691724849164064, 0.09416130878244185],
 'D_144': [0.12853387967152907, 0.16549843224843397, 0.09156932709462416],
 'D_66': [0.12554688776639272, 0.15737848957324732, 0.09371528595953815],
 'D_96': [0.12211802591722183, 0.1525404918654128, 0.09169555996903087],
 'D_94': [0.12119364823343642, 0.1513229008698755, 0.09106439559699735],
 'D_108': [0.12100011419855637, 0.1487730428852805, 0.09322718551183223],
 'D_86': [0.11982206064389206, 0.14802430104339726, 0.09161982024438685],
 'S_19': [0.11720598599634621, 0.13982147143726778, 0.09459050055542464],
 'B_36': [0.11471247680728952, 0.13587797815424985, 0.09354697546032921],
 'B_39': [0.11445601379280099, 0.133976490506799, 0.09493553707880298],
 'D_111': [0.11424612731530852, 0.13364928832637898, 0.09484296630423805],
 'B_27': [0.11287640958837497, 0.13213851951673714, 0.09361429966001279],
 'D_142': [0.1117788571651521, 0.12032446964050043, 0.10323324468980374],
 'D_87': [0.11095488233145982, 0.12673859288522416, 0.09517117177769549],
 'D_93': [0.11010347579452538, 0.12993361533833545, 0.09027333625071532],
 'S_18': [0.10785078464735542, 0.12505794994573585, 0.09064361934897498],
 'R_28': [0.10737620243731058, 0.12295585860606491, 0.09179654626855624],
 'D_109': [0.10680127046110877, 0.12281585764891496, 0.09078668327330258],
 'R_18': [0.10538944004074466, 0.12084216482919187, 0.08993671525229743],
 'R_23': [0.10328777131414385, 0.12135152135384061, 0.0852240212744471],
 'D_76': [0.07603517316580438, 0.10469094080429198, 0.047379405527316794],
 'B_29': [0.03709041430414565, 0.027070719879708806, 0.04711010872858249],
 'D_88': [0.03364855311616902, 0.014060495332550112, 0.05323661089978793],
 'D_110': [0.031562479511215914, 0.011706101514100455, 0.05141885750833137],
 'D_73': [0.031545007735506565, 0.01188154608669294, 0.05120846938432019],
 'B_42': [0.026878404166126194, 0.012487073926220142, 0.041269734406032245]}
## Learning 