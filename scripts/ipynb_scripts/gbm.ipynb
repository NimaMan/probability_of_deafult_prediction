{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "import random\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_type=\"train\"):\n",
    "    \n",
    "    if data_type == \"train\":\n",
    "        data = pd.read_parquet(OUTDIR+\"train_data.parquet\")\n",
    "        train_labels = pd.read_csv(DATADIR+\"train_labels.csv\")\n",
    "    else:\n",
    "        data = pd.read_parquet(OUTDIR+\"test_data.parquet\")\n",
    "        train_labels = None\n",
    "    \n",
    "    print('Starting feature engineer...')\n",
    "    \n",
    "    data_cont_agg = data.groupby(\"customer_ID\")[ContCols].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    data_cont_agg.columns = ['_'.join(x) for x in data_cont_agg.columns]\n",
    "    data_cont_agg.reset_index(inplace=True)\n",
    "\n",
    "    data_cat_agg = data.groupby(\"customer_ID\")[CATCOLS].agg(['count', 'last', 'nunique'])\n",
    "    data_cat_agg.columns = ['_'.join(x) for x in data_cat_agg.columns]\n",
    "    data_cat_agg.reset_index(inplace=True)\n",
    "    data = data_cont_agg.merge(data_cat_agg, how='inner', on='customer_ID')\n",
    "    \n",
    "    if train_labels is None:\n",
    "        data = data_cont_agg.merge(train_labels, how='inner', on='customer_ID')\n",
    "    \n",
    "    del data_cont_agg, data_cont_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    data.to_parquet(OUTDIR+f\"{data_type}_fe.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': \"binary_logloss\",\n",
    "        'boosting': 'dart',\n",
    "        'seed': 42,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pd.params import *\n",
    "train_data = np.load(OUTDIR+\"train_data_all.npy\").transpose((0, 2, 1))\n",
    "train_labels = np.load(OUTDIR+\"train_labels_all.npy\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=1/9, random_state=0, shuffle=True)\n",
    "validation_data = (X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 105606, number of negative: 302316\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.500823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 250862\n",
      "[LightGBM] [Info] Number of data points in the train set: 407922, number of used features: 1482\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258888 -> initscore=-1.051758\n",
      "[LightGBM] [Info] Start training from score -1.051758\n",
      "[500]\ttraining's binary_logloss: 0.342817\ttraining's amex_metric: 0.768143\tvalid_1's binary_logloss: 0.346463\tvalid_1's amex_metric: 0.756924\n",
      "[1000]\ttraining's binary_logloss: 0.252113\ttraining's amex_metric: 0.786198\tvalid_1's binary_logloss: 0.259272\tvalid_1's amex_metric: 0.769303\n",
      "[1500]\ttraining's binary_logloss: 0.228005\ttraining's amex_metric: 0.800063\tvalid_1's binary_logloss: 0.2386\tvalid_1's amex_metric: 0.774572\n",
      "[2000]\ttraining's binary_logloss: 0.214557\ttraining's amex_metric: 0.812215\tvalid_1's binary_logloss: 0.229507\tvalid_1's amex_metric: 0.778282\n",
      "[2500]\ttraining's binary_logloss: 0.207845\ttraining's amex_metric: 0.821381\tvalid_1's binary_logloss: 0.226471\tvalid_1's amex_metric: 0.782328\n",
      "[3000]\ttraining's binary_logloss: 0.201285\ttraining's amex_metric: 0.830621\tvalid_1's binary_logloss: 0.224034\tvalid_1's amex_metric: 0.783795\n",
      "[3500]\ttraining's binary_logloss: 0.195377\ttraining's amex_metric: 0.839383\tvalid_1's binary_logloss: 0.22226\tvalid_1's amex_metric: 0.786277\n",
      "[4000]\ttraining's binary_logloss: 0.190227\ttraining's amex_metric: 0.847756\tvalid_1's binary_logloss: 0.221138\tvalid_1's amex_metric: 0.787937\n",
      "[4500]\ttraining's binary_logloss: 0.185243\ttraining's amex_metric: 0.85588\tvalid_1's binary_logloss: 0.220315\tvalid_1's amex_metric: 0.788589\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=0'>1</a>\u001b[0m lgb_train \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_train\u001b[39m.\u001b[39mreshape(X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=1'>2</a>\u001b[0m lgb_valid \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_test\u001b[39m.\u001b[39mreshape(X_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), y_test,)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=3'>4</a>\u001b[0m             params \u001b[39m=\u001b[39;49m params,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=4'>5</a>\u001b[0m             train_set \u001b[39m=\u001b[39;49m lgb_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=5'>6</a>\u001b[0m             num_boost_round \u001b[39m=\u001b[39;49m \u001b[39m10500\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=6'>7</a>\u001b[0m             valid_sets \u001b[39m=\u001b[39;49m [lgb_train, lgb_valid],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=7'>8</a>\u001b[0m             early_stopping_rounds \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=8'>9</a>\u001b[0m             verbose_eval \u001b[39m=\u001b[39;49m \u001b[39m500\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=9'>10</a>\u001b[0m             feval \u001b[39m=\u001b[39;49m lgb_amex_metric\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/gbm.ipynb#ch0000005?line=10'>11</a>\u001b[0m             )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/q/lib/python3.9/site-packages/lightgbm/engine.py:249\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    242\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    243\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    244\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    245\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    246\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    247\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 249\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    251\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    252\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/q/lib/python3.9/site-packages/lightgbm/basic.py:2643\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2641\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   2642\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2643\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2644\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   2645\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   2646\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   2647\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "lgb_valid = lgb.Dataset(X_test.reshape(X_test.shape[0], -1), y_test,)\n",
    "model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 10500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval = 100,\n",
    "            feval = lgb_amex_metric\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, test=None, n_folds=5, seed=42):\n",
    "    cat_features = [f\"{cf}_last\" for cf in CATCOLS]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        if test is not None:\n",
    "            test[cat_col] = encoder.transform(test[cat_col])\n",
    "    # Round last float features to 2 decimal place\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    num_cols = [col for col in num_cols if 'last' in col]\n",
    "    for col in num_cols:\n",
    "        train[col + '_round2'] = train[col].round(2)\n",
    "        if test is not None:\n",
    "            test[col + '_round2'] = test[col].round(2)\n",
    "    # Get feature list\n",
    "    features = [col for col in train.columns if col not in ['customer_ID', \"S_2\", \"target\"]]\n",
    "    \n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[\"target\"])):\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[\"target\"].iloc[trn_ind], train[\"target\"].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 10500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval = 100,\n",
    "            feval = lgb_amex_metric\n",
    "            )\n",
    "        # Save best model\n",
    "        joblib.dump(model, OUTDIR+f'Models/lgbm_fold{fold}_seed{seed}.pkl')\n",
    "        val_pred = model.predict(x_val) # Predict validation\n",
    "        oof_predictions[val_ind] = val_pred  # Add to out of folds array\n",
    "        if test is not None:\n",
    "            test_pred = model.predict(test[features]) # Predict the test set\n",
    "            test_predictions += test_pred/n_folds\n",
    "        # Compute fold metric\n",
    "        score = amex_metric(y_val, val_pred)\n",
    "        print(f'Our fold {fold} CV score is {score}')\n",
    "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "        gc.collect()\n",
    "    score = amex_metric(train[\"target\"], oof_predictions)  # Compute out of folds metric\n",
    "    print(f'Our out of folds CV score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[\"target\"], 'prediction': oof_predictions})\n",
    "    oof_df.to_csv(OUTDIR+f'oof_lgbm_baseline_{n_folds}fold_seed{seed}.csv', index=False)\n",
    "    # Create a dataframe to store test prediction\n",
    "    if test is not None:\n",
    "        test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "        test_df.to_csv(f'/content/drive/MyDrive/Amex/Predictions/test_lgbm_baseline_{n_folds}fold_seed{seed}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_single_feature(train, feature, n_folds=5, seed=42):\n",
    "    cat_feature = \"auto\"\n",
    "    if feature in CATCOLS:\n",
    "        cat_feature = feature\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[\"target\"])):\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold} of {feature} feature...')\n",
    "        x_train, x_val = train[feature].iloc[trn_ind], train[feature].iloc[val_ind]\n",
    "        y_train, y_val = train[\"target\"].iloc[trn_ind], train[\"target\"].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_feature)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_feature)\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 10500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval = 100,\n",
    "            feval = lgb_amex_metric\n",
    "            )\n",
    "        # Save best model\n",
    "        joblib.dump(model, OUTDIR+f'Models/lgbm_fold{fold}_seed{seed}.pkl')\n",
    "        val_pred = model.predict(x_val) # Predict validation\n",
    "        oof_predictions[val_ind] = val_pred  # Add to out of folds array\n",
    "        # Compute fold metric\n",
    "        score = amex_metric(y_val, val_pred)\n",
    "        print(f'Our fold {fold} CV score is {score}')\n",
    "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "        gc.collect()\n",
    "    score = amex_metric(train[\"target\"], oof_predictions)  # Compute out of folds metric\n",
    "    print(f'Our out of folds CV score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[\"target\"], 'prediction': oof_predictions})\n",
    "    oof_df.to_csv(OUTDIR+f'oof_lgbm_baseline_{n_folds}fold_seed{seed}.csv', index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('q')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05e50049e3eb32775174019135b7208a0d3852fb22829b3658213f387a3fdcbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
