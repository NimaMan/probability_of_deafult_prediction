{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalvuate the eror \n",
    "The objective of the eval pred is to first figure out some info about the evaluation metric. The evaluation metric Consists of two parts. Ftist is a rank based one. We rank the customers that have defulted based on the predicted probability. choose the highest .04(#1 + #0*20). \n",
    "\n",
    "This is equvalent to the recall level of 4% the doc states. That is, of all the customers that are going to deafult, we aim to recall at least 96% of them!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q:\n",
    " - What does a recall of 4% mean? How do we train for a recall of a 4%? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pd.nn.conv import Conv\n",
    "from pd.data.loader import CustomerData\n",
    "from pd.nn.train_utils import train_torch_model\n",
    "from pd.metric import amex_metric\n",
    "from pd.params import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from bes.nn.es_module import ESModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_four_percent_captured(df) -> float:\n",
    "        \"\"\"Corresponds to the recall for a threshold of 4 %\"\"\"\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(OUTDIR+\"train13_raw_all_data.npy\")\n",
    "train_labels = np.load(OUTDIR+\"train13_raw_all_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_data = np.load(OUTDIR+\"train_raw_all_data.npy\", mmap_mode=\"r+\")\n",
    "train_labels = np.load(OUTDIR+\"train_raw_all_labels.npy\")\n",
    "class Data(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        return torch.from_numpy(self.data[index]), index\n",
    "\n",
    "train_dataset = Data(test_data, )\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"conv13_32_all\"\n",
    "model = Conv(conv_channels=32)\n",
    "model_param = torch.load(OUTDIR+model_name)\n",
    "model.load_state_dict(model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=1/9, random_state=1, shuffle=True)\n",
    "validation_data = (X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = validation_data\n",
    "val_features = torch.from_numpy(X_test)\n",
    "val_pred = model(val_features)\n",
    "val_metrix, val_gini, val_recall = amex_metric(y_test, val_pred.detach().numpy(), return_components=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8106466362523513, 0.9281171813848559, 0.6931760911198468)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrix, val_gini, val_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8076595984542532, 0.9279778102472538, 0.6873413866612527)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrix, val_gini, val_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load(OUTDIR+\"c13_preds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = amex_metric(train_labels, preds, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9189522846823319, 0.6626991745056633, 0.7908257295939976)\n",
      "(0.9117926612179975, 0.6322059953881629, 0.7719993283030802)\n",
      "(0.9137001253827733, 0.630639278172394, 0.7721697017775837)\n",
      "(0.910439040794739, 0.6391986391986392, 0.7748188399966891)\n",
      "(0.9143557163604561, 0.6452611218568666, 0.7798084191086614)\n",
      "(0.9117057372875503, 0.6510107015457788, 0.7813582194166646)\n",
      "(0.907421621330389, 0.6261520737327189, 0.7667868475315539)\n",
      "(0.9117512332341383, 0.6370797310278579, 0.7744154821309981)\n",
      "(0.9146816478243461, 0.6332438650306749, 0.7739627564275104)\n",
      "(0.911634259072624, 0.6298299845440495, 0.7707321218083367)\n",
      "(0.9122821673600039, 0.6259376233714963, 0.76910989536575)\n",
      "(0.9091516211022168, 0.630766223612197, 0.769958922357207)\n",
      "(0.9177579459881187, 0.6546998648909477, 0.7862289054395332)\n",
      "(0.9128007189670488, 0.6530612244897959, 0.7829309717284223)\n",
      "(0.9095910951030811, 0.6390001908032819, 0.7742956429531815)\n",
      "(0.9122655531659488, 0.6271450858034321, 0.7697053194846905)\n",
      "(0.9123261570727688, 0.6450300329393528, 0.7786780950060608)\n",
      "(0.9112252009857315, 0.6411483253588517, 0.7761867631722916)\n",
      "(0.9128061165021195, 0.647995396125072, 0.7804007563135957)\n",
      "(0.9111432155093143, 0.6408395449195763, 0.7759913802144454)\n",
      "(0.9123719250710762, 0.6445470282746683, 0.7784594766728723)\n",
      "(0.9146417224381, 0.6593047820241982, 0.7869732522311491)\n",
      "(0.9133694376600467, 0.639054470709147, 0.7762119541845969)\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros(len(train_dataset))\n",
    "model.eval()\n",
    "for idx, (feat, indices) in enumerate(train_loader):\n",
    "        batch_pred = model(feat)\n",
    "        preds[indices.numpy()] = batch_pred.detach().numpy().reshape(-1, )\n",
    "        #preds.append(batch_pred)\n",
    "        print(amex_metric(train_labels[indices.numpy()], preds[indices.numpy()], return_components=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47234747244543596, 0.09336767546683837, 0.28285757395613714)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=1/9, random_state=0, shuffle=True)\n",
    "validation_data = (X_test, y_test)\n",
    "\n",
    "train_dataset = CustomerData(X_train, train_labels=y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, BCE loss: 0.746, amex train: 0.033, val 0.000\n",
      "0, BCE loss: 0.880, amex train: 0.146, val 0.000\n",
      "0, BCE loss: 0.725, amex train: 0.220, val 0.000\n",
      "0, BCE loss: 0.568, amex train: 0.288, val 0.000\n",
      "0, BCE loss: 0.526, amex train: 0.314, val 0.000\n",
      "0, BCE loss: 0.582, amex train: 0.345, val 0.000\n",
      "0, BCE loss: 0.607, amex train: 0.355, val 0.000\n",
      "0, BCE loss: 0.571, amex train: 0.358, val 0.000\n",
      "0, BCE loss: 0.529, amex train: 0.384, val 0.000\n",
      "0, BCE loss: 0.511, amex train: 0.386, val 0.000\n",
      "0, BCE loss: 0.519, amex train: 0.391, val 0.000\n",
      "0, BCE loss: 0.531, amex train: 0.378, val 0.000\n",
      "0, BCE loss: 0.546, amex train: 0.387, val 0.000\n",
      "0, BCE loss: 0.537, amex train: 0.388, val 0.000\n",
      "0, BCE loss: 0.542, amex train: 0.388, val 0.000\n",
      "0, BCE loss: 0.529, amex train: 0.396, val 0.000\n",
      "0, BCE loss: 0.520, amex train: 0.399, val 0.000\n",
      "0, BCE loss: 0.494, amex train: 0.387, val 0.000\n",
      "1, BCE loss: 0.507, amex train: 0.408, val 0.000\n",
      "1, BCE loss: 0.503, amex train: 0.387, val 0.000\n",
      "1, BCE loss: 0.511, amex train: 0.393, val 0.000\n",
      "1, BCE loss: 0.513, amex train: 0.409, val 0.000\n",
      "1, BCE loss: 0.522, amex train: 0.393, val 0.000\n",
      "1, BCE loss: 0.514, amex train: 0.400, val 0.000\n",
      "1, BCE loss: 0.512, amex train: 0.403, val 0.000\n",
      "1, BCE loss: 0.507, amex train: 0.400, val 0.000\n",
      "1, BCE loss: 0.500, amex train: 0.421, val 0.000\n",
      "1, BCE loss: 0.496, amex train: 0.414, val 0.000\n",
      "1, BCE loss: 0.499, amex train: 0.420, val 0.000\n",
      "1, BCE loss: 0.500, amex train: 0.403, val 0.000\n",
      "1, BCE loss: 0.504, amex train: 0.407, val 0.000\n",
      "1, BCE loss: 0.495, amex train: 0.404, val 0.000\n",
      "1, BCE loss: 0.499, amex train: 0.403, val 0.000\n",
      "1, BCE loss: 0.492, amex train: 0.404, val 0.000\n",
      "1, BCE loss: 0.489, amex train: 0.406, val 0.000\n",
      "1, BCE loss: 0.472, amex train: 0.400, val 0.000\n",
      "2, BCE loss: 0.482, amex train: 0.413, val 0.000\n",
      "2, BCE loss: 0.479, amex train: 0.393, val 0.000\n",
      "2, BCE loss: 0.482, amex train: 0.401, val 0.000\n",
      "2, BCE loss: 0.477, amex train: 0.416, val 0.000\n",
      "2, BCE loss: 0.485, amex train: 0.396, val 0.000\n",
      "2, BCE loss: 0.474, amex train: 0.399, val 0.000\n",
      "2, BCE loss: 0.472, amex train: 0.396, val 0.000\n",
      "2, BCE loss: 0.466, amex train: 0.398, val 0.000\n",
      "2, BCE loss: 0.457, amex train: 0.419, val 0.000\n",
      "2, BCE loss: 0.451, amex train: 0.412, val 0.000\n",
      "2, BCE loss: 0.450, amex train: 0.424, val 0.000\n",
      "2, BCE loss: 0.450, amex train: 0.406, val 0.000\n",
      "2, BCE loss: 0.448, amex train: 0.416, val 0.000\n",
      "2, BCE loss: 0.439, amex train: 0.415, val 0.000\n",
      "2, BCE loss: 0.439, amex train: 0.411, val 0.000\n",
      "2, BCE loss: 0.433, amex train: 0.420, val 0.000\n",
      "2, BCE loss: 0.426, amex train: 0.435, val 0.000\n",
      "2, BCE loss: 0.409, amex train: 0.434, val 0.000\n",
      "3, BCE loss: 0.411, amex train: 0.463, val 0.000\n",
      "3, BCE loss: 0.409, amex train: 0.456, val 0.000\n",
      "3, BCE loss: 0.404, amex train: 0.474, val 0.000\n",
      "3, BCE loss: 0.390, amex train: 0.504, val 0.000\n",
      "3, BCE loss: 0.398, amex train: 0.498, val 0.000\n",
      "3, BCE loss: 0.383, amex train: 0.519, val 0.000\n",
      "3, BCE loss: 0.373, amex train: 0.541, val 0.000\n",
      "3, BCE loss: 0.354, amex train: 0.555, val 0.000\n",
      "3, BCE loss: 0.338, amex train: 0.581, val 0.000\n",
      "3, BCE loss: 0.335, amex train: 0.582, val 0.000\n",
      "3, BCE loss: 0.335, amex train: 0.592, val 0.000\n",
      "3, BCE loss: 0.319, amex train: 0.619, val 0.000\n",
      "3, BCE loss: 0.318, amex train: 0.622, val 0.000\n",
      "3, BCE loss: 0.310, amex train: 0.624, val 0.000\n",
      "3, BCE loss: 0.311, amex train: 0.633, val 0.000\n",
      "3, BCE loss: 0.303, amex train: 0.644, val 0.000\n",
      "3, BCE loss: 0.302, amex train: 0.647, val 0.000\n",
      "3, BCE loss: 0.313, amex train: 0.632, val 0.000\n",
      "4, BCE loss: 0.294, amex train: 0.663, val 0.000\n",
      "4, BCE loss: 0.290, amex train: 0.668, val 0.000\n",
      "4, BCE loss: 0.286, amex train: 0.676, val 0.000\n",
      "4, BCE loss: 0.284, amex train: 0.674, val 0.000\n",
      "4, BCE loss: 0.288, amex train: 0.685, val 0.000\n",
      "4, BCE loss: 0.292, amex train: 0.670, val 0.000\n",
      "4, BCE loss: 0.281, amex train: 0.684, val 0.000\n",
      "4, BCE loss: 0.277, amex train: 0.691, val 0.000\n",
      "4, BCE loss: 0.267, amex train: 0.707, val 0.000\n",
      "4, BCE loss: 0.274, amex train: 0.694, val 0.000\n",
      "4, BCE loss: 0.278, amex train: 0.679, val 0.000\n",
      "4, BCE loss: 0.265, amex train: 0.708, val 0.000\n",
      "4, BCE loss: 0.268, amex train: 0.709, val 0.000\n",
      "4, BCE loss: 0.268, amex train: 0.697, val 0.000\n",
      "4, BCE loss: 0.272, amex train: 0.702, val 0.000\n",
      "4, BCE loss: 0.263, amex train: 0.715, val 0.000\n",
      "4, BCE loss: 0.264, amex train: 0.713, val 0.000\n",
      "4, BCE loss: 0.267, amex train: 0.702, val 0.000\n",
      "5, BCE loss: 0.262, amex train: 0.713, val 0.000\n",
      "5, BCE loss: 0.268, amex train: 0.716, val 0.000\n",
      "5, BCE loss: 0.259, amex train: 0.719, val 0.000\n",
      "5, BCE loss: 0.263, amex train: 0.716, val 0.000\n",
      "5, BCE loss: 0.264, amex train: 0.719, val 0.000\n",
      "5, BCE loss: 0.269, amex train: 0.711, val 0.000\n",
      "5, BCE loss: 0.260, amex train: 0.719, val 0.000\n",
      "5, BCE loss: 0.254, amex train: 0.737, val 0.000\n",
      "5, BCE loss: 0.247, amex train: 0.740, val 0.000\n",
      "5, BCE loss: 0.255, amex train: 0.726, val 0.000\n",
      "5, BCE loss: 0.260, amex train: 0.712, val 0.000\n",
      "5, BCE loss: 0.248, amex train: 0.740, val 0.000\n",
      "5, BCE loss: 0.249, amex train: 0.740, val 0.000\n",
      "5, BCE loss: 0.255, amex train: 0.726, val 0.000\n",
      "5, BCE loss: 0.253, amex train: 0.732, val 0.000\n",
      "5, BCE loss: 0.247, amex train: 0.743, val 0.000\n",
      "5, BCE loss: 0.250, amex train: 0.736, val 0.000\n",
      "5, BCE loss: 0.256, amex train: 0.723, val 0.000\n",
      "6, BCE loss: 0.248, amex train: 0.735, val 0.000\n",
      "6, BCE loss: 0.244, amex train: 0.739, val 0.000\n",
      "6, BCE loss: 0.249, amex train: 0.742, val 0.000\n",
      "6, BCE loss: 0.246, amex train: 0.738, val 0.000\n",
      "6, BCE loss: 0.255, amex train: 0.741, val 0.000\n",
      "6, BCE loss: 0.252, amex train: 0.734, val 0.000\n",
      "6, BCE loss: 0.245, amex train: 0.740, val 0.000\n",
      "6, BCE loss: 0.240, amex train: 0.755, val 0.000\n",
      "6, BCE loss: 0.235, amex train: 0.763, val 0.000\n",
      "6, BCE loss: 0.241, amex train: 0.747, val 0.000\n",
      "6, BCE loss: 0.252, amex train: 0.732, val 0.000\n",
      "6, BCE loss: 0.235, amex train: 0.757, val 0.000\n",
      "6, BCE loss: 0.239, amex train: 0.754, val 0.000\n",
      "6, BCE loss: 0.242, amex train: 0.746, val 0.000\n",
      "6, BCE loss: 0.244, amex train: 0.751, val 0.000\n",
      "6, BCE loss: 0.239, amex train: 0.759, val 0.000\n",
      "6, BCE loss: 0.241, amex train: 0.754, val 0.000\n",
      "6, BCE loss: 0.243, amex train: 0.746, val 0.000\n",
      "7, BCE loss: 0.234, amex train: 0.752, val 0.000\n",
      "7, BCE loss: 0.237, amex train: 0.753, val 0.000\n",
      "7, BCE loss: 0.246, amex train: 0.754, val 0.000\n",
      "7, BCE loss: 0.243, amex train: 0.750, val 0.000\n",
      "7, BCE loss: 0.248, amex train: 0.756, val 0.000\n",
      "7, BCE loss: 0.241, amex train: 0.749, val 0.000\n",
      "7, BCE loss: 0.236, amex train: 0.754, val 0.000\n",
      "7, BCE loss: 0.231, amex train: 0.766, val 0.000\n",
      "7, BCE loss: 0.227, amex train: 0.774, val 0.000\n",
      "7, BCE loss: 0.232, amex train: 0.761, val 0.000\n",
      "7, BCE loss: 0.245, amex train: 0.741, val 0.000\n",
      "7, BCE loss: 0.229, amex train: 0.768, val 0.000\n",
      "7, BCE loss: 0.230, amex train: 0.764, val 0.000\n",
      "7, BCE loss: 0.236, amex train: 0.758, val 0.000\n",
      "7, BCE loss: 0.234, amex train: 0.766, val 0.000\n",
      "7, BCE loss: 0.230, amex train: 0.770, val 0.000\n",
      "7, BCE loss: 0.240, amex train: 0.762, val 0.000\n",
      "7, BCE loss: 0.243, amex train: 0.761, val 0.000\n",
      "8, BCE loss: 0.245, amex train: 0.764, val 0.000\n",
      "8, BCE loss: 0.237, amex train: 0.759, val 0.000\n",
      "8, BCE loss: 0.233, amex train: 0.762, val 0.000\n",
      "8, BCE loss: 0.234, amex train: 0.767, val 0.000\n",
      "8, BCE loss: 0.237, amex train: 0.766, val 0.000\n",
      "8, BCE loss: 0.239, amex train: 0.758, val 0.000\n",
      "8, BCE loss: 0.238, amex train: 0.758, val 0.000\n",
      "8, BCE loss: 0.226, amex train: 0.771, val 0.000\n",
      "8, BCE loss: 0.228, amex train: 0.778, val 0.000\n",
      "8, BCE loss: 0.227, amex train: 0.765, val 0.000\n",
      "8, BCE loss: 0.243, amex train: 0.751, val 0.000\n",
      "8, BCE loss: 0.229, amex train: 0.774, val 0.000\n",
      "8, BCE loss: 0.225, amex train: 0.770, val 0.000\n",
      "8, BCE loss: 0.234, amex train: 0.766, val 0.000\n",
      "8, BCE loss: 0.229, amex train: 0.772, val 0.000\n",
      "8, BCE loss: 0.228, amex train: 0.775, val 0.000\n",
      "8, BCE loss: 0.234, amex train: 0.767, val 0.000\n",
      "8, BCE loss: 0.230, amex train: 0.767, val 0.000\n",
      "9, BCE loss: 0.224, amex train: 0.772, val 0.000\n",
      "9, BCE loss: 0.225, amex train: 0.766, val 0.000\n",
      "9, BCE loss: 0.230, amex train: 0.767, val 0.000\n",
      "9, BCE loss: 0.228, amex train: 0.770, val 0.000\n",
      "9, BCE loss: 0.234, amex train: 0.770, val 0.000\n",
      "9, BCE loss: 0.232, amex train: 0.768, val 0.000\n",
      "9, BCE loss: 0.229, amex train: 0.769, val 0.000\n",
      "9, BCE loss: 0.221, amex train: 0.779, val 0.000\n",
      "9, BCE loss: 0.218, amex train: 0.786, val 0.769\n",
      "9, BCE loss: 0.224, amex train: 0.774, val 0.000\n",
      "9, BCE loss: 0.235, amex train: 0.757, val 0.000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "model_name = \"conv_all_13\"\n",
    "\n",
    "model = Conv(input_dim=X_train.shape[-1], conv_channels=25)\n",
    "model = train_torch_model(model, train_loader, num_epochs=50, validation_data=validation_data, \n",
    "                        output_model_name=model_name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343141, 13, 188)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D analysis of GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pd.params import *\n",
    "def get_agg_data(data_dir=\"train_agg_mean_q5_q95_q5_q95.npz\"):\n",
    "    d = np.load(OUTDIR+data_dir)\n",
    "    #train_data = np.concatenate((d[\"d2\"].astype(np.int32), d[\"d1\"].reshape(d[\"d1\"].shape[0], -1)), axis=1)\n",
    "    train_labels = d[\"labels\"]\n",
    "    df2 = pd.DataFrame(d[\"d2\"].astype(np.int32))\n",
    "    df = pd.DataFrame(d[\"d1\"].reshape(d[\"d1\"].shape[0], -1))\n",
    "    df = pd.concat((df2, df), axis=1,)\n",
    "    df.columns = [f\"c{i}\" for i in range(df.shape[1])]\n",
    "    cat_indices = list(np.arange(d[\"d2\"].shape[1]))\n",
    "\n",
    "    return df, train_labels, cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train_labels, cat_indices = get_agg_data(data_dir=\"train_agg_mean_q5_q95_q5_q95.npz\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, train_labels, test_size=1/9, random_state=0, shuffle=True)\n",
    "validation_data = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "model = lgb.Booster(model_file=OUTDIR+\"lgbm_agg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9247766447649399, 0.6687252211039951, 0.7967509329344675)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(y_test, y_pred, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"pred\":y_pred, \"target\":y_test.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"pred\", ascending=False, inplace=True)\n",
    "df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "df['weight_cumsum'] = df['weight'].cumsum()\n",
    "#df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_pct_cutoff = int(0.04 * df['weight'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"pred\", \"weight\"], ascending=False).reset_index(drop=True).to_csv(OUTDIR+\"pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target  c0\n",
       "1.0     13    7440\n",
       "0.0     13     932\n",
       "1.0     12     189\n",
       "        10     141\n",
       "        8      126\n",
       "        9      110\n",
       "        2      109\n",
       "        7      105\n",
       "        11     102\n",
       "        6      101\n",
       "        3      101\n",
       "        5       94\n",
       "        1       82\n",
       "        4       71\n",
       "0.0     9       25\n",
       "        12      22\n",
       "        1       18\n",
       "        4       17\n",
       "        3       17\n",
       "        2       14\n",
       "        10      14\n",
       "        7       10\n",
       "        6       10\n",
       "        11       9\n",
       "        8        8\n",
       "        5        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cutoff[[\"target\", \"c0\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4345, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.loc[df['weight_cumsum'] >= four_pct_cutoff]\n",
    "a[a.target == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_cutoff[df_cutoff.c0==13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(a, x=\"feature\", y=['gbm_recall', 'gbm_gini'], hue=\"target\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis of the C13 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(OUTDIR+\"train13_raw_all_data.npy\")\n",
    "train_labels = np.load(OUTDIR+\"train13_raw_all_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=1/9, random_state=0, shuffle=True)\n",
    "validation_data = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import lightgbm as lgb \n",
    "\n",
    "model = joblib.load(OUTDIR+f'lgbm13.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9323274209347154, 0.6966805400466958, 0.8145039804907056)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.reshape(X_test.shape[0], -1))\n",
    "amex_metric(y_test, y_pred, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50991,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(OUTDIR+'train_agg1_mean_q5_q95_q5_q95_id.json', 'r') as f:\n",
    "            train_id_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_customers_count = pd.read_parquet(TRAINDATA).customer_ID.value_counts().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_dict1 = {val:key for key, val in train_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EA for Ensemble\n",
    " - get the indices of the c13 and other \n",
    " - split data into the train- val for the 13 and the rest \n",
    " - investigate how use other probs in combination with the C13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pd.utils import get_customers_data_indices, get_customers_id_from_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(PREDDIR, \"train_pred.csv\"), index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "c13_indices, other_indices = get_customers_data_indices(num_data_points=[13], id_dir=f'train_agg{1}_mean_q5_q95_q5_q95_id.json')\n",
    "c13 = get_customers_id_from_indices(c13_indices)\n",
    "co = get_customers_id_from_indices(other_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbm13_p0_agg4 (0.7784211269909311, 0.9153520328218663, 0.641490221159996)\n",
      "catb13_agg4 (0.7800931240548388, 0.9163817575855585, 0.6438044905241189)\n",
      "xgbm_p0_agg4 (0.7835301255381706, 0.9182148611009147, 0.6488453899754266)\n",
      "catb_agg4 (0.7852057909753889, 0.9193781554856348, 0.651033426465143)\n",
      "xgbm13_p0_agg1 (0.7803124979124139, 0.9143547564872979, 0.6462702393375299)\n",
      "catb13_agg1 (0.7827671015956867, 0.9159903246442297, 0.6495438785471438)\n",
      "xgbm_p0_agg1 (0.7884289087744241, 0.9211706057805782, 0.65568721176827)\n",
      "catb_agg1 (0.791248008817272, 0.9222475913377114, 0.6602484262968324)\n",
      "xgbm13_p0_agg2 (0.780711393613778, 0.9150515615905006, 0.6463712256370553)\n",
      "catb13_agg2 (0.7843004509212151, 0.9173486717283158, 0.6512522301141145)\n",
      "xgbm_p0_agg2 (0.7867236616624773, 0.9202342758950559, 0.6532130474298987)\n",
      "catb_agg2 (0.7905246330788464, 0.9219369357305206, 0.6591123304271721)\n",
      "xgbm13_p0_agg0 (0.7783887239555718, 0.9151778249266618, 0.6415996229844818)\n",
      "catb13_agg0 (0.7805501417581232, 0.916984418568591, 0.6441158649476554)\n",
      "xgbm_p0_agg0 (0.7820801108738411, 0.9176711787611808, 0.6464890429865014)\n",
      "catb_agg0 (0.7856119926601796, 0.9193742529340528, 0.6518497323863063)\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns[1:]:\n",
    "    print(col, amex_metric(df.target.values.reshape(-1), df[col].values.reshape(-1), return_components=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6620866932343902, 0.8499996215624771, 0.47417376490630325)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(df.loc[co].target.values.reshape(-1), df.loc[co].xgbm_agg1.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7890485361667914, 0.9213410888953358, 0.6567559834382469)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(df.target.values.reshape(-1), df.xgbm_agg1.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8411921213824842"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c13)/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.815346149869002, 0.9311683944204957, 0.6995239053175082)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(df.loc[c13].target.values.reshape(-1), df.loc[c13].xgbm_p0_agg1.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20204069\\Anaconda3\\envs\\p8\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "df[\"mp\"] = 0\n",
    "df[\"mp\"].loc[c13]= df.loc[c13].xgbm13_p0_agg1.values.reshape(-1)\n",
    "df[\"mp\"].loc[co] = df.loc[co].catb_agg0.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7869155426505532, 0.9202730013478294, 0.653558083953277)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(df.target.values.reshape(-1), df.mp.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>xgbm13_p0_agg4</th>\n",
       "      <th>catb13_agg4</th>\n",
       "      <th>xgbm_p0_agg4</th>\n",
       "      <th>catb_agg4</th>\n",
       "      <th>xgbm13_p0_agg1</th>\n",
       "      <th>catb13_agg1</th>\n",
       "      <th>xgbm_p0_agg1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000fd6641609c6ece5454664794f0340ad84dddce9a267a310b5ae68e9d8e5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00001b22f846c82c51f6e3958ccd81970162bae8b007e80662ef27519fcc18c1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000041bdba6ecadd89a52d11886e8eaaec9325906c9723355abb5ca523658edc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018017</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad51ca8b8c4a24cefed</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4081a6acc28cf4f8af7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd3e5b57cfcbee30286</th>\n",
       "      <td>0</td>\n",
       "      <td>0.030506</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>0.026186</td>\n",
       "      <td>0.016143</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff9984b999fccb2b6127635ed0736dda94e544e67e026eee4d20f680639ff6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145b2c3d01967fcce461</th>\n",
       "      <td>1</td>\n",
       "      <td>0.078081</td>\n",
       "      <td>0.084864</td>\n",
       "      <td>0.079191</td>\n",
       "      <td>0.091721</td>\n",
       "      <td>0.067533</td>\n",
       "      <td>0.064484</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eaba8b115f71cab04681</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    target  xgbm13_p0_agg4  \\\n",
       "customer_ID                                                                  \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...       0        0.001161   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...       0        0.001499   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...       0        0.001104   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...       0        0.018017   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...       0        0.002971   \n",
       "...                                                    ...             ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...       0        0.002730   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...       0        0.030506   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...       0        0.001327   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...       1        0.078081   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...       0        0.002845   \n",
       "\n",
       "                                                    catb13_agg4  xgbm_p0_agg4  \\\n",
       "customer_ID                                                                     \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...     0.000529      0.000842   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...     0.000868      0.001189   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...     0.001431      0.001254   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...     0.009783      0.016114   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...     0.003396      0.002746   \n",
       "...                                                         ...           ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...     0.004286      0.002113   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...     0.028569      0.020954   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...     0.001241      0.002094   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...     0.084864      0.079191   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...     0.002024      0.002896   \n",
       "\n",
       "                                                    catb_agg4  xgbm13_p0_agg1  \\\n",
       "customer_ID                                                                     \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...   0.000445        0.001045   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...   0.000648        0.001601   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...   0.001210        0.001626   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...   0.009630        0.012393   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...   0.003013        0.001842   \n",
       "...                                                       ...             ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...   0.003219        0.003145   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...   0.026186        0.016143   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...   0.001248        0.002010   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...   0.091721        0.067533   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...   0.002245        0.002009   \n",
       "\n",
       "                                                    catb13_agg1  xgbm_p0_agg1  \n",
       "customer_ID                                                                    \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...     0.000503           NaN  \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...     0.001390           NaN  \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...     0.001561           NaN  \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...     0.005425           NaN  \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...     0.003420           NaN  \n",
       "...                                                         ...           ...  \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...     0.003823           NaN  \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...     0.023527           NaN  \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...     0.001161           NaN  \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...     0.064484           NaN  \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...          NaN           NaN  \n",
       "\n",
       "[458913 rows x 8 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_metric(train_labels[indices.numpy()], preds[indices.numpy()], return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"pred\", ascending=False, inplace=True)\n",
    "df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "df['weight_cumsum'] = df['weight'].cumsum()\n",
    "#df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "    pred_dir = os.path.join(DATADIR, \"PRED\", \"train_pred.csv\")\n",
    "    pred_file = pd.read_csv(pred_dir, index_col=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('q')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05e50049e3eb32775174019135b7208a0d3852fb22829b3658213f387a3fdcbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
