{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalvuate the eror \n",
    "The objective of the eval pred is to first figure out some info about the evaluation metric. The evaluation metric Consists of two parts. Ftist is a rank based one. We rank the customers that have defulted based on the predicted probability. choose the highest .04(#1 + #0*20). \n",
    "\n",
    "This is equvalent to the recall level of 4% the doc states. That is, of all the customers that are going to deafult, we aim to recall at least 96% of them!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q:\n",
    " - What does a recall of 4% mean? How do we train for a recall of a 4%? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pd.nn.conv import Conv\n",
    "from pd.data.loader import CustomerData\n",
    "from pd.nn.train_utils import train_torch_model\n",
    "from pd.metric import amex_metric\n",
    "from pd.params import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from bes.nn.es_module import ESModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_four_percent_captured(df) -> float:\n",
    "        \"\"\"Corresponds to the recall for a threshold of 4 %\"\"\"\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(OUTDIR+\"train13_raw_all_data.npy\")\n",
    "train_labels = np.load(OUTDIR+\"train13_raw_all_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_data = np.load(OUTDIR+\"train_raw_all_data.npy\", mmap_mode=\"r+\")\n",
    "train_labels = np.load(OUTDIR+\"train_raw_all_labels.npy\")\n",
    "class Data(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        return torch.from_numpy(self.data[index]), index\n",
    "\n",
    "train_dataset = Data(test_data, )\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"conv13_32_all\"\n",
    "model = Conv(conv_channels=32)\n",
    "model_param = torch.load(OUTDIR+model_name)\n",
    "model.load_state_dict(model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=1/9, random_state=1, shuffle=True)\n",
    "validation_data = (X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = validation_data\n",
    "val_features = torch.from_numpy(X_test)\n",
    "val_pred = model(val_features)\n",
    "val_metrix, val_gini, val_recall = amex_metric(y_test, val_pred.detach().numpy(), return_components=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8106466362523513, 0.9281171813848559, 0.6931760911198468)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrix, val_gini, val_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8076595984542532, 0.9279778102472538, 0.6873413866612527)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrix, val_gini, val_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load(OUTDIR+\"c13_preds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = amex_metric(train_labels, preds, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9189522846823319, 0.6626991745056633, 0.7908257295939976)\n",
      "(0.9117926612179975, 0.6322059953881629, 0.7719993283030802)\n",
      "(0.9137001253827733, 0.630639278172394, 0.7721697017775837)\n",
      "(0.910439040794739, 0.6391986391986392, 0.7748188399966891)\n",
      "(0.9143557163604561, 0.6452611218568666, 0.7798084191086614)\n",
      "(0.9117057372875503, 0.6510107015457788, 0.7813582194166646)\n",
      "(0.907421621330389, 0.6261520737327189, 0.7667868475315539)\n",
      "(0.9117512332341383, 0.6370797310278579, 0.7744154821309981)\n",
      "(0.9146816478243461, 0.6332438650306749, 0.7739627564275104)\n",
      "(0.911634259072624, 0.6298299845440495, 0.7707321218083367)\n",
      "(0.9122821673600039, 0.6259376233714963, 0.76910989536575)\n",
      "(0.9091516211022168, 0.630766223612197, 0.769958922357207)\n",
      "(0.9177579459881187, 0.6546998648909477, 0.7862289054395332)\n",
      "(0.9128007189670488, 0.6530612244897959, 0.7829309717284223)\n",
      "(0.9095910951030811, 0.6390001908032819, 0.7742956429531815)\n",
      "(0.9122655531659488, 0.6271450858034321, 0.7697053194846905)\n",
      "(0.9123261570727688, 0.6450300329393528, 0.7786780950060608)\n",
      "(0.9112252009857315, 0.6411483253588517, 0.7761867631722916)\n",
      "(0.9128061165021195, 0.647995396125072, 0.7804007563135957)\n",
      "(0.9111432155093143, 0.6408395449195763, 0.7759913802144454)\n",
      "(0.9123719250710762, 0.6445470282746683, 0.7784594766728723)\n",
      "(0.9146417224381, 0.6593047820241982, 0.7869732522311491)\n",
      "(0.9133694376600467, 0.639054470709147, 0.7762119541845969)\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros(len(train_dataset))\n",
    "model.eval()\n",
    "for idx, (feat, indices) in enumerate(train_loader):\n",
    "        batch_pred = model(feat)\n",
    "        preds[indices.numpy()] = batch_pred.detach().numpy().reshape(-1, )\n",
    "        #preds.append(batch_pred)\n",
    "        print(amex_metric(train_labels[indices.numpy()], preds[indices.numpy()], return_components=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47234747244543596, 0.09336767546683837, 0.28285757395613714)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=1/9, random_state=0, shuffle=True)\n",
    "validation_data = (X_test, y_test)\n",
    "\n",
    "train_dataset = CustomerData(X_train, train_labels=y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, BCE loss: 0.746, amex train: 0.033, val 0.000\n",
      "0, BCE loss: 0.880, amex train: 0.146, val 0.000\n",
      "0, BCE loss: 0.725, amex train: 0.220, val 0.000\n",
      "0, BCE loss: 0.568, amex train: 0.288, val 0.000\n",
      "0, BCE loss: 0.526, amex train: 0.314, val 0.000\n",
      "0, BCE loss: 0.582, amex train: 0.345, val 0.000\n",
      "0, BCE loss: 0.607, amex train: 0.355, val 0.000\n",
      "0, BCE loss: 0.571, amex train: 0.358, val 0.000\n",
      "0, BCE loss: 0.529, amex train: 0.384, val 0.000\n",
      "0, BCE loss: 0.511, amex train: 0.386, val 0.000\n",
      "0, BCE loss: 0.519, amex train: 0.391, val 0.000\n",
      "0, BCE loss: 0.531, amex train: 0.378, val 0.000\n",
      "0, BCE loss: 0.546, amex train: 0.387, val 0.000\n",
      "0, BCE loss: 0.537, amex train: 0.388, val 0.000\n",
      "0, BCE loss: 0.542, amex train: 0.388, val 0.000\n",
      "0, BCE loss: 0.529, amex train: 0.396, val 0.000\n",
      "0, BCE loss: 0.520, amex train: 0.399, val 0.000\n",
      "0, BCE loss: 0.494, amex train: 0.387, val 0.000\n",
      "1, BCE loss: 0.507, amex train: 0.408, val 0.000\n",
      "1, BCE loss: 0.503, amex train: 0.387, val 0.000\n",
      "1, BCE loss: 0.511, amex train: 0.393, val 0.000\n",
      "1, BCE loss: 0.513, amex train: 0.409, val 0.000\n",
      "1, BCE loss: 0.522, amex train: 0.393, val 0.000\n",
      "1, BCE loss: 0.514, amex train: 0.400, val 0.000\n",
      "1, BCE loss: 0.512, amex train: 0.403, val 0.000\n",
      "1, BCE loss: 0.507, amex train: 0.400, val 0.000\n",
      "1, BCE loss: 0.500, amex train: 0.421, val 0.000\n",
      "1, BCE loss: 0.496, amex train: 0.414, val 0.000\n",
      "1, BCE loss: 0.499, amex train: 0.420, val 0.000\n",
      "1, BCE loss: 0.500, amex train: 0.403, val 0.000\n",
      "1, BCE loss: 0.504, amex train: 0.407, val 0.000\n",
      "1, BCE loss: 0.495, amex train: 0.404, val 0.000\n",
      "1, BCE loss: 0.499, amex train: 0.403, val 0.000\n",
      "1, BCE loss: 0.492, amex train: 0.404, val 0.000\n",
      "1, BCE loss: 0.489, amex train: 0.406, val 0.000\n",
      "1, BCE loss: 0.472, amex train: 0.400, val 0.000\n",
      "2, BCE loss: 0.482, amex train: 0.413, val 0.000\n",
      "2, BCE loss: 0.479, amex train: 0.393, val 0.000\n",
      "2, BCE loss: 0.482, amex train: 0.401, val 0.000\n",
      "2, BCE loss: 0.477, amex train: 0.416, val 0.000\n",
      "2, BCE loss: 0.485, amex train: 0.396, val 0.000\n",
      "2, BCE loss: 0.474, amex train: 0.399, val 0.000\n",
      "2, BCE loss: 0.472, amex train: 0.396, val 0.000\n",
      "2, BCE loss: 0.466, amex train: 0.398, val 0.000\n",
      "2, BCE loss: 0.457, amex train: 0.419, val 0.000\n",
      "2, BCE loss: 0.451, amex train: 0.412, val 0.000\n",
      "2, BCE loss: 0.450, amex train: 0.424, val 0.000\n",
      "2, BCE loss: 0.450, amex train: 0.406, val 0.000\n",
      "2, BCE loss: 0.448, amex train: 0.416, val 0.000\n",
      "2, BCE loss: 0.439, amex train: 0.415, val 0.000\n",
      "2, BCE loss: 0.439, amex train: 0.411, val 0.000\n",
      "2, BCE loss: 0.433, amex train: 0.420, val 0.000\n",
      "2, BCE loss: 0.426, amex train: 0.435, val 0.000\n",
      "2, BCE loss: 0.409, amex train: 0.434, val 0.000\n",
      "3, BCE loss: 0.411, amex train: 0.463, val 0.000\n",
      "3, BCE loss: 0.409, amex train: 0.456, val 0.000\n",
      "3, BCE loss: 0.404, amex train: 0.474, val 0.000\n",
      "3, BCE loss: 0.390, amex train: 0.504, val 0.000\n",
      "3, BCE loss: 0.398, amex train: 0.498, val 0.000\n",
      "3, BCE loss: 0.383, amex train: 0.519, val 0.000\n",
      "3, BCE loss: 0.373, amex train: 0.541, val 0.000\n",
      "3, BCE loss: 0.354, amex train: 0.555, val 0.000\n",
      "3, BCE loss: 0.338, amex train: 0.581, val 0.000\n",
      "3, BCE loss: 0.335, amex train: 0.582, val 0.000\n",
      "3, BCE loss: 0.335, amex train: 0.592, val 0.000\n",
      "3, BCE loss: 0.319, amex train: 0.619, val 0.000\n",
      "3, BCE loss: 0.318, amex train: 0.622, val 0.000\n",
      "3, BCE loss: 0.310, amex train: 0.624, val 0.000\n",
      "3, BCE loss: 0.311, amex train: 0.633, val 0.000\n",
      "3, BCE loss: 0.303, amex train: 0.644, val 0.000\n",
      "3, BCE loss: 0.302, amex train: 0.647, val 0.000\n",
      "3, BCE loss: 0.313, amex train: 0.632, val 0.000\n",
      "4, BCE loss: 0.294, amex train: 0.663, val 0.000\n",
      "4, BCE loss: 0.290, amex train: 0.668, val 0.000\n",
      "4, BCE loss: 0.286, amex train: 0.676, val 0.000\n",
      "4, BCE loss: 0.284, amex train: 0.674, val 0.000\n",
      "4, BCE loss: 0.288, amex train: 0.685, val 0.000\n",
      "4, BCE loss: 0.292, amex train: 0.670, val 0.000\n",
      "4, BCE loss: 0.281, amex train: 0.684, val 0.000\n",
      "4, BCE loss: 0.277, amex train: 0.691, val 0.000\n",
      "4, BCE loss: 0.267, amex train: 0.707, val 0.000\n",
      "4, BCE loss: 0.274, amex train: 0.694, val 0.000\n",
      "4, BCE loss: 0.278, amex train: 0.679, val 0.000\n",
      "4, BCE loss: 0.265, amex train: 0.708, val 0.000\n",
      "4, BCE loss: 0.268, amex train: 0.709, val 0.000\n",
      "4, BCE loss: 0.268, amex train: 0.697, val 0.000\n",
      "4, BCE loss: 0.272, amex train: 0.702, val 0.000\n",
      "4, BCE loss: 0.263, amex train: 0.715, val 0.000\n",
      "4, BCE loss: 0.264, amex train: 0.713, val 0.000\n",
      "4, BCE loss: 0.267, amex train: 0.702, val 0.000\n",
      "5, BCE loss: 0.262, amex train: 0.713, val 0.000\n",
      "5, BCE loss: 0.268, amex train: 0.716, val 0.000\n",
      "5, BCE loss: 0.259, amex train: 0.719, val 0.000\n",
      "5, BCE loss: 0.263, amex train: 0.716, val 0.000\n",
      "5, BCE loss: 0.264, amex train: 0.719, val 0.000\n",
      "5, BCE loss: 0.269, amex train: 0.711, val 0.000\n",
      "5, BCE loss: 0.260, amex train: 0.719, val 0.000\n",
      "5, BCE loss: 0.254, amex train: 0.737, val 0.000\n",
      "5, BCE loss: 0.247, amex train: 0.740, val 0.000\n",
      "5, BCE loss: 0.255, amex train: 0.726, val 0.000\n",
      "5, BCE loss: 0.260, amex train: 0.712, val 0.000\n",
      "5, BCE loss: 0.248, amex train: 0.740, val 0.000\n",
      "5, BCE loss: 0.249, amex train: 0.740, val 0.000\n",
      "5, BCE loss: 0.255, amex train: 0.726, val 0.000\n",
      "5, BCE loss: 0.253, amex train: 0.732, val 0.000\n",
      "5, BCE loss: 0.247, amex train: 0.743, val 0.000\n",
      "5, BCE loss: 0.250, amex train: 0.736, val 0.000\n",
      "5, BCE loss: 0.256, amex train: 0.723, val 0.000\n",
      "6, BCE loss: 0.248, amex train: 0.735, val 0.000\n",
      "6, BCE loss: 0.244, amex train: 0.739, val 0.000\n",
      "6, BCE loss: 0.249, amex train: 0.742, val 0.000\n",
      "6, BCE loss: 0.246, amex train: 0.738, val 0.000\n",
      "6, BCE loss: 0.255, amex train: 0.741, val 0.000\n",
      "6, BCE loss: 0.252, amex train: 0.734, val 0.000\n",
      "6, BCE loss: 0.245, amex train: 0.740, val 0.000\n",
      "6, BCE loss: 0.240, amex train: 0.755, val 0.000\n",
      "6, BCE loss: 0.235, amex train: 0.763, val 0.000\n",
      "6, BCE loss: 0.241, amex train: 0.747, val 0.000\n",
      "6, BCE loss: 0.252, amex train: 0.732, val 0.000\n",
      "6, BCE loss: 0.235, amex train: 0.757, val 0.000\n",
      "6, BCE loss: 0.239, amex train: 0.754, val 0.000\n",
      "6, BCE loss: 0.242, amex train: 0.746, val 0.000\n",
      "6, BCE loss: 0.244, amex train: 0.751, val 0.000\n",
      "6, BCE loss: 0.239, amex train: 0.759, val 0.000\n",
      "6, BCE loss: 0.241, amex train: 0.754, val 0.000\n",
      "6, BCE loss: 0.243, amex train: 0.746, val 0.000\n",
      "7, BCE loss: 0.234, amex train: 0.752, val 0.000\n",
      "7, BCE loss: 0.237, amex train: 0.753, val 0.000\n",
      "7, BCE loss: 0.246, amex train: 0.754, val 0.000\n",
      "7, BCE loss: 0.243, amex train: 0.750, val 0.000\n",
      "7, BCE loss: 0.248, amex train: 0.756, val 0.000\n",
      "7, BCE loss: 0.241, amex train: 0.749, val 0.000\n",
      "7, BCE loss: 0.236, amex train: 0.754, val 0.000\n",
      "7, BCE loss: 0.231, amex train: 0.766, val 0.000\n",
      "7, BCE loss: 0.227, amex train: 0.774, val 0.000\n",
      "7, BCE loss: 0.232, amex train: 0.761, val 0.000\n",
      "7, BCE loss: 0.245, amex train: 0.741, val 0.000\n",
      "7, BCE loss: 0.229, amex train: 0.768, val 0.000\n",
      "7, BCE loss: 0.230, amex train: 0.764, val 0.000\n",
      "7, BCE loss: 0.236, amex train: 0.758, val 0.000\n",
      "7, BCE loss: 0.234, amex train: 0.766, val 0.000\n",
      "7, BCE loss: 0.230, amex train: 0.770, val 0.000\n",
      "7, BCE loss: 0.240, amex train: 0.762, val 0.000\n",
      "7, BCE loss: 0.243, amex train: 0.761, val 0.000\n",
      "8, BCE loss: 0.245, amex train: 0.764, val 0.000\n",
      "8, BCE loss: 0.237, amex train: 0.759, val 0.000\n",
      "8, BCE loss: 0.233, amex train: 0.762, val 0.000\n",
      "8, BCE loss: 0.234, amex train: 0.767, val 0.000\n",
      "8, BCE loss: 0.237, amex train: 0.766, val 0.000\n",
      "8, BCE loss: 0.239, amex train: 0.758, val 0.000\n",
      "8, BCE loss: 0.238, amex train: 0.758, val 0.000\n",
      "8, BCE loss: 0.226, amex train: 0.771, val 0.000\n",
      "8, BCE loss: 0.228, amex train: 0.778, val 0.000\n",
      "8, BCE loss: 0.227, amex train: 0.765, val 0.000\n",
      "8, BCE loss: 0.243, amex train: 0.751, val 0.000\n",
      "8, BCE loss: 0.229, amex train: 0.774, val 0.000\n",
      "8, BCE loss: 0.225, amex train: 0.770, val 0.000\n",
      "8, BCE loss: 0.234, amex train: 0.766, val 0.000\n",
      "8, BCE loss: 0.229, amex train: 0.772, val 0.000\n",
      "8, BCE loss: 0.228, amex train: 0.775, val 0.000\n",
      "8, BCE loss: 0.234, amex train: 0.767, val 0.000\n",
      "8, BCE loss: 0.230, amex train: 0.767, val 0.000\n",
      "9, BCE loss: 0.224, amex train: 0.772, val 0.000\n",
      "9, BCE loss: 0.225, amex train: 0.766, val 0.000\n",
      "9, BCE loss: 0.230, amex train: 0.767, val 0.000\n",
      "9, BCE loss: 0.228, amex train: 0.770, val 0.000\n",
      "9, BCE loss: 0.234, amex train: 0.770, val 0.000\n",
      "9, BCE loss: 0.232, amex train: 0.768, val 0.000\n",
      "9, BCE loss: 0.229, amex train: 0.769, val 0.000\n",
      "9, BCE loss: 0.221, amex train: 0.779, val 0.000\n",
      "9, BCE loss: 0.218, amex train: 0.786, val 0.769\n",
      "9, BCE loss: 0.224, amex train: 0.774, val 0.000\n",
      "9, BCE loss: 0.235, amex train: 0.757, val 0.000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "model_name = \"conv_all_13\"\n",
    "\n",
    "model = Conv(input_dim=X_train.shape[-1], conv_channels=25)\n",
    "model = train_torch_model(model, train_loader, num_epochs=50, validation_data=validation_data, \n",
    "                        output_model_name=model_name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343141, 13, 188)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D analysis of GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pd.params import *\n",
    "def get_agg_data(data_dir=\"train_agg_mean_q5_q95_q5_q95.npz\"):\n",
    "    d = np.load(OUTDIR+data_dir)\n",
    "    #train_data = np.concatenate((d[\"d2\"].astype(np.int32), d[\"d1\"].reshape(d[\"d1\"].shape[0], -1)), axis=1)\n",
    "    train_labels = d[\"labels\"]\n",
    "    df2 = pd.DataFrame(d[\"d2\"].astype(np.int32))\n",
    "    df = pd.DataFrame(d[\"d1\"].reshape(d[\"d1\"].shape[0], -1))\n",
    "    df = pd.concat((df2, df), axis=1,)\n",
    "    df.columns = [f\"c{i}\" for i in range(df.shape[1])]\n",
    "    cat_indices = list(np.arange(d[\"d2\"].shape[1]))\n",
    "\n",
    "    return df, train_labels, cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train_labels, cat_indices = get_agg_data(data_dir=\"train_agg_mean_q5_q95_q5_q95.npz\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, train_labels, test_size=1/9, random_state=0, shuffle=True)\n",
    "validation_data = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "model = lgb.Booster(model_file=OUTDIR+\"lgbm_agg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9247766447649399, 0.6687252211039951, 0.7967509329344675)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(y_test, y_pred, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"pred\":y_pred, \"target\":y_test.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"pred\", ascending=False, inplace=True)\n",
    "df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "df['weight_cumsum'] = df['weight'].cumsum()\n",
    "#df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_pct_cutoff = int(0.04 * df['weight'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"pred\", \"weight\"], ascending=False).reset_index(drop=True).to_csv(OUTDIR+\"pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target  c0\n",
       "1.0     13    7440\n",
       "0.0     13     932\n",
       "1.0     12     189\n",
       "        10     141\n",
       "        8      126\n",
       "        9      110\n",
       "        2      109\n",
       "        7      105\n",
       "        11     102\n",
       "        6      101\n",
       "        3      101\n",
       "        5       94\n",
       "        1       82\n",
       "        4       71\n",
       "0.0     9       25\n",
       "        12      22\n",
       "        1       18\n",
       "        4       17\n",
       "        3       17\n",
       "        2       14\n",
       "        10      14\n",
       "        7       10\n",
       "        6       10\n",
       "        11       9\n",
       "        8        8\n",
       "        5        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cutoff[[\"target\", \"c0\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4345, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.loc[df['weight_cumsum'] >= four_pct_cutoff]\n",
    "a[a.target == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_cutoff[df_cutoff.c0==13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(a, x=\"feature\", y=['gbm_recall', 'gbm_gini'], hue=\"target\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis of the C13 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(OUTDIR+\"train13_raw_all_data.npy\")\n",
    "train_labels = np.load(OUTDIR+\"train13_raw_all_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=1/9, random_state=0, shuffle=True)\n",
    "validation_data = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import lightgbm as lgb \n",
    "\n",
    "model = joblib.load(OUTDIR+f'lgbm13.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9323274209347154, 0.6966805400466958, 0.8145039804907056)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.reshape(X_test.shape[0], -1))\n",
    "amex_metric(y_test, y_pred, return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50991,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(OUTDIR+'train_agg1_mean_q5_q95_q5_q95_id.json', 'r') as f:\n",
    "            train_id_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_customers_count = pd.read_parquet(TRAINDATA).customer_ID.value_counts().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_dict1 = {val:key for key, val in train_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EA for Ensemble\n",
    " - get the indices of the c13 and other \n",
    " - split data into the train- val for the 13 and the rest \n",
    " - investigate how use other probs in combination with the C13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pd.utils import get_customers_data_indices, get_customers_id_from_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PREDDIR+\"train_pred.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c13_indices, other_indices = get_customers_data_indices(num_data_points=[13], id_dir=f'train_agg{1}_mean_q5_q95_q5_q95_id.json')\n",
    "c13 = get_customers_id_from_indices(c13_indices)\n",
    "co = get_customers_id_from_indices(other_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm13_agg1 (0.7838867741175084, 0.9155198706506092, 0.6522536775844077)\n",
      "lgbm_agg1 (0.7932525928055224, 0.923782594975841, 0.6627225906352038)\n",
      "xgbm13_agg1 (0.7803792021838198, 0.9141599595566524, 0.6465984448109873)\n",
      "xgbm_agg1 (0.7890485361667914, 0.9213410888953358, 0.6567559834382469)\n",
      "catb13_agg1 (0.782928953236126, 0.9160363156014134, 0.6498215908708386)\n",
      "xgbm13_agg2 (0.019606480060928782, -0.00039050034200617577, 0.03960346046386374)\n",
      "catb_agg1 (0.7912651133544574, 0.9222397227872801, 0.6602905039216347)\n",
      "xgbm_agg2 (0.019552792231331984, -0.0004389673264766379, 0.039544551789140604)\n",
      "xgbm13_agg3 (0.01948767129421065, -0.0004766384261543881, 0.03945198101457569)\n",
      "xgbm13_agg0 (0.019461779178026235, -0.00040218978411651175, 0.03932574814016898)\n",
      "catb13_agg0 (0.019988080942495445, -3.965930193474984e-05, 0.04001582118692564)\n",
      "catb13_agg3 (0.020047814758487503, 0.00016396357965383395, 0.03993166593732117)\n",
      "xgbm_agg3 (0.019804481002760232, -0.00023013315723578804, 0.03983909516275625)\n",
      "xgbm_agg0 (0.019556100847442144, -0.00022196197024514335, 0.03933416366512943)\n",
      "catb_agg0 (0.019868093554569873, 9.064902047377177e-05, 0.03964553808866597)\n",
      "catb_agg3 (0.02003838818164651, 0.00019560357573452923, 0.03988117278755849)\n",
      "catb13_agg2 (0.020107451461814047, 0.0002327438365442437, 0.03998215908708385)\n",
      "catb_agg2 (0.019917153389121967, 0.00019718421453841252, 0.039637122563705524)\n",
      "catb13_agg4 (0.019899005173278205, 0.00036286038190161196, 0.039435149964654796)\n",
      "catb_agg4 (0.01989585948036406, 0.00040706214583600573, 0.039384656814892116)\n",
      "xgbm13_agg4 (0.020309930685284815, 0.0013866840049655616, 0.03923317736560407)\n",
      "conv13_agg1 (0.12009241847966105, 0.17363486557210697, 0.06654997138721513)\n",
      "lgbm13_agg4 (0.019920298438099046, 0.0006663281853171617, 0.039174268690880934)\n",
      "lgbm_agg4 (0.01980068330791816, 0.0006711481488083436, 0.038930218467027974)\n",
      "xgbm_p1_agg4 (0.020281967837725227, 0.0007921647123777799, 0.039771770963072675)\n",
      "xgbm_p1_agg0 (0.019827787988250654, -0.00030133653570120364, 0.039956912512202514)\n",
      "xgbm13_p1_agg2 (0.019369117124707444, -0.0009830435638951093, 0.039721277813309995)\n",
      "mp (0.7931060130914598, 0.9236156684221223, 0.6625963577607972)\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns[1:]:\n",
    "    print(col, amex_metric(df.target.values.reshape(-1), df[col].values.reshape(-1), return_components=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8142794254216831, 0.9309572057462473, 0.6976016450971189)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "amex_metric(df.loc[c13].target.values.reshape(-1), df.loc[c13].xgbm13_agg1.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6620866932343902, 0.8499996215624771, 0.47417376490630325)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(df.loc[co].target.values.reshape(-1), df.loc[co].xgbm_agg1.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lgbm_agg0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/error_analysis.ipynb Cell 67\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nimamanaf/Desktop/kaggle/pd/pd/scripts/ipynb_scripts/error_analysis.ipynb#Y144sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m amex_metric(df\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), df\u001b[39m.\u001b[39;49mlgbm_agg0\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), return_components\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/q/lib/python3.9/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lgbm_agg0'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7890485361667914, 0.9213410888953358, 0.6567559834382469)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(df.target.values.reshape(-1), df.xgbm_agg1.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the c13 from 13 preds and the rest from others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_metric(df.loc[c13].target.values.reshape(-1), df.loc[c13].xgbm13_agg1.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/_nykd9tn43dfx142nv5r8l900000gn/T/ipykernel_20168/2280686262.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"mp\"].loc[c13]= df.loc[c13].lgbm13_agg1.values.reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "df[\"mp\"] = 0\n",
    "df[\"mp\"].loc[c13]= df.loc[c13].lgbm13_agg1.values.reshape(-1)\n",
    "df[\"mp\"].loc[co] = df.loc[co].lgbm_agg1.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7931060130914598, 0.9236156684221223, 0.6625963577607972)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(df.target.values.reshape(-1), df.mp.values.reshape(-1), return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>lgbm13_agg1</th>\n",
       "      <th>lgbm_agg1</th>\n",
       "      <th>xgbm13_agg1</th>\n",
       "      <th>xgbm_agg1</th>\n",
       "      <th>catb13_agg1</th>\n",
       "      <th>xgbm13_agg2</th>\n",
       "      <th>catb_agg1</th>\n",
       "      <th>xgbm_agg2</th>\n",
       "      <th>xgbm13_agg3</th>\n",
       "      <th>...</th>\n",
       "      <th>catb13_agg4</th>\n",
       "      <th>catb_agg4</th>\n",
       "      <th>xgbm13_agg4</th>\n",
       "      <th>conv13_agg1</th>\n",
       "      <th>lgbm13_agg4</th>\n",
       "      <th>lgbm_agg4</th>\n",
       "      <th>xgbm_p1_agg4</th>\n",
       "      <th>xgbm_p1_agg0</th>\n",
       "      <th>xgbm13_p1_agg2</th>\n",
       "      <th>mp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.084060</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.411908</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319579</td>\n",
       "      <td>0.233948</td>\n",
       "      <td>0.248878</td>\n",
       "      <td>0.057720</td>\n",
       "      <td>0.223292</td>\n",
       "      <td>0.221504</td>\n",
       "      <td>0.278566</td>\n",
       "      <td>0.473031</td>\n",
       "      <td>0.394507</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000fd6641609c6ece5454664794f0340ad84dddce9a267a310b5ae68e9d8e5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.030730</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00001b22f846c82c51f6e3958ccd81970162bae8b007e80662ef27519fcc18c1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.708267</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.682479</td>\n",
       "      <td>0.721939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926558</td>\n",
       "      <td>0.852145</td>\n",
       "      <td>0.845415</td>\n",
       "      <td>0.989080</td>\n",
       "      <td>0.898360</td>\n",
       "      <td>0.875647</td>\n",
       "      <td>0.923688</td>\n",
       "      <td>0.758849</td>\n",
       "      <td>0.747954</td>\n",
       "      <td>0.001328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000041bdba6ecadd89a52d11886e8eaaec9325906c9723355abb5ca523658edc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006624</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.228898</td>\n",
       "      <td>0.036013</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.014978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad51ca8b8c4a24cefed</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.173564</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.097903</td>\n",
       "      <td>0.141820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686741</td>\n",
       "      <td>0.532207</td>\n",
       "      <td>0.869929</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.613125</td>\n",
       "      <td>0.569500</td>\n",
       "      <td>0.554354</td>\n",
       "      <td>0.130969</td>\n",
       "      <td>0.166047</td>\n",
       "      <td>0.002276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4081a6acc28cf4f8af7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.080117</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.087961</td>\n",
       "      <td>0.070516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783628</td>\n",
       "      <td>0.803240</td>\n",
       "      <td>0.772201</td>\n",
       "      <td>0.968079</td>\n",
       "      <td>0.735141</td>\n",
       "      <td>0.772904</td>\n",
       "      <td>0.748484</td>\n",
       "      <td>0.097006</td>\n",
       "      <td>0.118654</td>\n",
       "      <td>0.003260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd3e5b57cfcbee30286</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>0.015333</td>\n",
       "      <td>0.023504</td>\n",
       "      <td>0.641878</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.703336</td>\n",
       "      <td>0.671222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.289117</td>\n",
       "      <td>0.025283</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>0.009717</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.641897</td>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff9984b999fccb2b6127635ed0736dda94e544e67e026eee4d20f680639ff6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.067844</td>\n",
       "      <td>0.086980</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.037413</td>\n",
       "      <td>0.057313</td>\n",
       "      <td>0.043447</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>0.039908</td>\n",
       "      <td>0.002635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145b2c3d01967fcce461</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121188</td>\n",
       "      <td>0.137636</td>\n",
       "      <td>0.051029</td>\n",
       "      <td>0.099376</td>\n",
       "      <td>0.064224</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.069920</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644011</td>\n",
       "      <td>0.684420</td>\n",
       "      <td>0.890430</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.639953</td>\n",
       "      <td>0.714162</td>\n",
       "      <td>0.687799</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.016684</td>\n",
       "      <td>0.051029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eaba8b115f71cab04681</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.119131</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.141710</td>\n",
       "      <td>0.111623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858527</td>\n",
       "      <td>0.834750</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.795577</td>\n",
       "      <td>0.823785</td>\n",
       "      <td>0.771725</td>\n",
       "      <td>0.143544</td>\n",
       "      <td>0.162103</td>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    target  lgbm13_agg1  \\\n",
       "customer_ID                                                               \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...       0     0.000785   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...       0     0.001388   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...       0     0.000769   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...       0     0.006624   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...       0     0.001455   \n",
       "...                                                    ...          ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...       0     0.005207   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...       0     0.012799   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...       0     0.001078   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...       1     0.121188   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...       0     0.001826   \n",
       "\n",
       "                                                    lgbm_agg1  xgbm13_agg1  \\\n",
       "customer_ID                                                                  \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...   0.000865     0.000929   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...   0.001169     0.001767   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...   0.000928     0.001328   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...   0.006822     0.014978   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...   0.001415     0.002276   \n",
       "...                                                       ...          ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...   0.005179     0.003260   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...   0.013453     0.020431   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...   0.001216     0.002635   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...   0.137636     0.051029   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...   0.002198     0.001909   \n",
       "\n",
       "                                                    xgbm_agg1  catb13_agg1  \\\n",
       "customer_ID                                                                  \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...   0.001096     0.000507   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...   0.001736     0.001521   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...   0.001397     0.001477   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...   0.015899     0.005526   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...   0.001929     0.003260   \n",
       "...                                                       ...          ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...   0.002894     0.003879   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...   0.015333     0.023504   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...   0.002300     0.001189   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...   0.099376     0.064224   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...   0.001901     0.001592   \n",
       "\n",
       "                                                    xgbm13_agg2  catb_agg1  \\\n",
       "customer_ID                                                                  \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...     0.084060   0.000377   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...     0.001192   0.001198   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...     0.708267   0.001522   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...     0.004889   0.007509   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...     0.173564   0.002790   \n",
       "...                                                         ...        ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...     0.080117   0.005118   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...     0.641878   0.021071   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...     0.002700   0.001184   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...     0.001614   0.069920   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...     0.119131   0.001621   \n",
       "\n",
       "                                                    xgbm_agg2  xgbm13_agg3  \\\n",
       "customer_ID                                                                  \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...   0.411908     0.086643   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...   0.001043     0.001298   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...   0.682479     0.721939   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...   0.005005     0.004198   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...   0.097903     0.141820   \n",
       "...                                                       ...          ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...   0.087961     0.070516   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...   0.703336     0.671222   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...   0.003638     0.003095   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...   0.001069     0.001413   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...   0.141710     0.111623   \n",
       "\n",
       "                                                    ...  catb13_agg4  \\\n",
       "customer_ID                                         ...                \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...  ...     0.319579   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...  ...     0.007746   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...  ...     0.926558   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...  ...     0.002244   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...  ...     0.686741   \n",
       "...                                                 ...          ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...  ...     0.783628   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...  ...     0.007948   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...  ...     0.050234   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...  ...     0.644011   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...  ...     0.858527   \n",
       "\n",
       "                                                    catb_agg4  xgbm13_agg4  \\\n",
       "customer_ID                                                                  \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...   0.233948     0.248878   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...   0.009628     0.030730   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...   0.852145     0.845415   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...   0.002142     0.228898   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...   0.532207     0.869929   \n",
       "...                                                       ...          ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...   0.803240     0.772201   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...   0.007321     0.289117   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...   0.067844     0.086980   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...   0.684420     0.890430   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...   0.834750     0.803648   \n",
       "\n",
       "                                                    conv13_agg1  lgbm13_agg4  \\\n",
       "customer_ID                                                                    \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...     0.057720     0.223292   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...     0.005716     0.004263   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...     0.989080     0.898360   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...     0.036013     0.002851   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...     0.012256     0.613125   \n",
       "...                                                         ...          ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...     0.968079     0.735141   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...     0.025283     0.010784   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...     0.003368     0.037413   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...     0.066303     0.639953   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...     0.003640     0.795577   \n",
       "\n",
       "                                                    lgbm_agg4  xgbm_p1_agg4  \\\n",
       "customer_ID                                                                   \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...   0.221504      0.278566   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...   0.007139      0.010354   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...   0.875647      0.923688   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...   0.001793      0.002868   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...   0.569500      0.554354   \n",
       "...                                                       ...           ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...   0.772904      0.748484   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...   0.009717      0.010460   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...   0.057313      0.043447   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...   0.714162      0.687799   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...   0.823785      0.771725   \n",
       "\n",
       "                                                    xgbm_p1_agg0  \\\n",
       "customer_ID                                                        \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...      0.473031   \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...      0.001710   \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...      0.758849   \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...      0.006334   \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...      0.130969   \n",
       "...                                                          ...   \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...      0.097006   \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...      0.641897   \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...      0.006240   \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...      0.003592   \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...      0.143544   \n",
       "\n",
       "                                                    xgbm13_p1_agg2        mp  \n",
       "customer_ID                                                                   \n",
       "0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fb...        0.394507  0.000929  \n",
       "00000fd6641609c6ece5454664794f0340ad84dddce9a26...        0.008161  0.001767  \n",
       "00001b22f846c82c51f6e3958ccd81970162bae8b007e80...        0.747954  0.001328  \n",
       "000041bdba6ecadd89a52d11886e8eaaec9325906c97233...        0.011321  0.014978  \n",
       "00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8ad...        0.166047  0.002276  \n",
       "...                                                            ...       ...  \n",
       "ffff41c8a52833b56430603969b9ca48d208e7c192c6a40...        0.118654  0.003260  \n",
       "ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fdd...        0.664796  0.020431  \n",
       "ffff9984b999fccb2b6127635ed0736dda94e544e67e026...        0.039908  0.002635  \n",
       "ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf388145...        0.016684  0.051029  \n",
       "fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eab...        0.162103  0.001909  \n",
       "\n",
       "[458913 rows x 29 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_metric(train_labels[indices.numpy()], preds[indices.numpy()], return_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"pred\", ascending=False, inplace=True)\n",
    "df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "df['weight_cumsum'] = df['weight'].cumsum()\n",
    "#df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('q')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05e50049e3eb32775174019135b7208a0d3852fb22829b3658213f387a3fdcbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
